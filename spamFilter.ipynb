{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# NLP libraries\n",
    "import nltk\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "import re as regex\n",
    "# Text embedding libraries\n",
    "import gensim as gsm\n",
    "from gensim.models import Word2Vec, Doc2Vec\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "# ML libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import recall_score, precision_score, accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Spam_Email_Data.csv')\n",
    "cleaned_data = data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocessing(text):\n",
    "    text = ' '.join(word for word in text.split() if '@' not in word)\n",
    "    text = ''.join(char for char in text if char.isalpha() or char.isspace())\n",
    "    text = ''.join(char for char in text if char not in ['<', '>'])\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    stemmer = PorterStemmer()\n",
    "    filter_text = [stemmer.stem(token) for token in tokens if token not in stop_words]\n",
    "    return ' '.join(filter_text)\n",
    "\n",
    "cleaned_data['text'] = cleaned_data['text'].apply(data_preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mon jul returnpath deliveredto receiv localhos...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mon jun returnpath deliveryd tue jun receiv ma...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mon jul returnpath deliveredto receiv localhos...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mon jun returnpath deliveryd mon jun receiv ma...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mon aug returnpath deliveredto receiv localhos...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target\n",
       "0  mon jul returnpath deliveredto receiv localhos...       0\n",
       "1  mon jun returnpath deliveryd tue jun receiv ma...       1\n",
       "2  mon jul returnpath deliveredto receiv localhos...       1\n",
       "3  mon jun returnpath deliveryd mon jun receiv ma...       1\n",
       "4  mon aug returnpath deliveredto receiv localhos...       0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "x_train, x_test, y_train, y_test = train_test_split(cleaned_data['text'], cleaned_data['target'], test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text embedding techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [rec.split() for rec in x_train]\n",
    "documents = [TaggedDocument(rec, [i]) for i, rec in enumerate(words)]\n",
    "word2vec = Word2Vec(words)\n",
    "dec2vec = Doc2Vec(documents)\n",
    "def word2vec_embedding(text):\n",
    "    bag = text.split()\n",
    "    return np.mean([word2vec.wv[word] for word in bag if word in word2vec.wv], axis=0)\n",
    "def doc2vec_embedding(text):\n",
    "    return dec2vec.infer_vector(text.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfid = TfidfVectorizer()\n",
    "bow = CountVectorizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "models ={\n",
    "    \"Logistic Regression with Word2Vec\":LogisticRegression(max_iter=1000) ,\n",
    "    \"SVM with Word2Vec\": SVC(),\n",
    "    \"Logistic Regression with Doc2Vec\": LogisticRegression(max_iter=1000),\n",
    "    \"SVM with Doc2Vec\": SVC(),\n",
    "    \"Logistic Regression with TFID\": LogisticRegression(max_iter=1000),\n",
    "    \"SVM with TFID\": SVC(),\n",
    "    \"Logistic Regression with BOW\": LogisticRegression(max_iter=1000),\n",
    "    \"SVM with BOW\": SVC()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word2vec\n",
    "x_train_word2vec = np.array([word2vec_embedding(text) for text in x_train])\n",
    "x_test_word2vec = np.array([word2vec_embedding(text) for text in x_test])\n",
    "#doc2vec\n",
    "x_train_doc2vec = np.array([doc2vec_embedding(text) for text in x_train])\n",
    "x_test_doc2vec = np.array([doc2vec_embedding(text) for text in x_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tfid\n",
    "x_train_tfid = tfid.fit_transform(x_train)\n",
    "x_test_tfid = tfid.transform(x_test)\n",
    "#bow\n",
    "x_train_bow = bow.fit_transform(x_train)\n",
    "x_test_bow = bow.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "def get_model_evaluation(model,y_test,y_pred):\n",
    "    recall = recall_score(y_test,y_pred)\n",
    "    precision = precision_score(y_test,y_pred)\n",
    "    accuracy = accuracy_score(y_test,y_pred)\n",
    "    f1 = f1_score(y_test,y_pred)\n",
    "    results.append({'Model': model, 'Recall': recall, 'Precision': precision, 'Accuracy': accuracy, 'F1-Score': f1})\n",
    "\n",
    "\n",
    "for model in models:\n",
    "    if 'Word2Vec' in model:\n",
    "        models[model].fit(x_train_word2vec,y_train)\n",
    "        y_pred = models[model].predict(x_test_word2vec)\n",
    "        get_model_evaluation(model,y_test,y_pred)\n",
    "    elif 'Doc2Vec' in model:\n",
    "        models[model].fit(x_train_doc2vec,y_train)\n",
    "        y_pred = models[model].predict(x_test_doc2vec)\n",
    "        get_model_evaluation(model,y_test,y_pred)\n",
    "    elif 'TFID' in model:\n",
    "        models[model].fit(x_train_tfid,y_train)\n",
    "        y_pred = models[model].predict(x_test_tfid)\n",
    "        get_model_evaluation(model,y_test,y_pred)\n",
    "    else:\n",
    "        models[model].fit(x_train_bow,y_train)\n",
    "        y_pred = models[model].predict(x_test_bow)\n",
    "        get_model_evaluation(model,y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               Model    Recall  Precision  Accuracy  F1-Score\n",
      "0  Logistic Regression with Word2Vec  0.956522   0.988235  0.981712  0.972120\n",
      "1                  SVM with Word2Vec  0.950311   0.992432  0.981021  0.970915\n",
      "2   Logistic Regression with Doc2Vec  0.897516   0.961197  0.953761  0.928266\n",
      "3                   SVM with Doc2Vec  0.890269   0.975057  0.955832  0.930736\n",
      "4      Logistic Regression with TFID  0.922360   0.997760  0.973430  0.958580\n",
      "5                      SVM with TFID  0.967909   0.998932  0.988958  0.983176\n",
      "6       Logistic Regression with BOW  0.987578   0.996865  0.994824  0.992200\n",
      "7                       SVM with BOW  0.964803   0.988335  0.984472  0.976427\n"
     ]
    }
   ],
   "source": [
    "print(pd.DataFrame(results))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
